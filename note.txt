# 录制数据的流程

首先执行时间同步.打开workspace下的timesync.sh文件,
先执行第一条命令,然后重复多次执行第二条,直到*号对上的时钟延迟<10ms.

初始化:
sudo bash start.sh
    启动rtk定位:
    这个launch文件在:/opt/ros/noetic/share/nmea_navsat_driver/launch/nmea_serial_driver.launch


列出可以录制的topic:
rostopic list

查看对应topic的数据
rostopic hz <topic name>

修改ros_record.sh文件中的topic以选择需要录制的数据

选好需要的topic以后开始录制数据:
bash ros_record.sh
------------------------------------------------
# 查看数据

查看录制包信息:
rosbag info bagname.bag

播放查看录制的包:
打开rviz
rosrun rviz rviz -d sensor.rviz
启动roscore并循环播放包:
roscore
rosbag play bagname.bag -l


使用PlotJuggler可视化数据图
roscore
rosrun plotjuggler plotjuggler  


-------------------------------------------------------------------
# 传感器标定

双目相机标定结果位置:
/home/hcp/Workspace/ros_ws/src/zed-ros-wrapper/zed_wrapper/params/zed2_calibration.yaml
相应的相机参数设置:
general:
    camera_model:               'zed2'
    grab_resolution:            'HD2K'     # 'HD2K', 'HD1080', 'HD720', 'VGA', 'AUTO'
    grab_frame_rate:            15          # Frequency of frame grabbing for internal SDK operations
depth:
    min_depth:                  0.2         # Min: 0.2, Max: 3.0 - Default 0.7 - Note: reducing this value will require more computational power and GPU memory
    max_depth:                  20.0        # Max: 40.0


lidar2lidar标定结果:
/home/hcp/Workspace/src/fast_gicp/lidar_calibration.yaml
/home/hcp/Workspace/src/fast_gicp/lidar_calibration_2.yaml
这两个结果分别用不同的场景视频计算得到,对比差别不大


